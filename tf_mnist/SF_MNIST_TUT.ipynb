{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution() #Включаем режим динамического графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#В режиме статического графа\n",
    "#В таком режиме сначала строится полный граф нейронной сети, затем он замораживается и изменять его больше нельзя.\n",
    "\n",
    "#В режиме динамического графа (жадного выполнения)\n",
    "#Такой режим используется во многих фреймворках. \n",
    "#В этом случае граф описывается с помощью произвольного python кода, и потом #есть возможность менять этот код в ходе работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#ПАРАМЕТРЫ ДЛЯ СЕТИ\n",
    "\n",
    "NUM_EPOCHS = 10 # колличество эпох в сети\n",
    "BATCH_SIZE = 64 # Батч - колличество образцов показываемых на одной итерации градиентного спуска.\n",
    "LEARNING_RATE = 0.0001 #скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x,train_y),(test_x,test_y) = tf.keras.datasets.mnist.load_data() #загружаем dataset mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) uint8\n",
      "(60000,) uint8\n",
      "(10000, 28, 28) uint8\n",
      "(10000,) uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,train_x.dtype)\n",
    "print(train_y.shape,train_y.dtype)\n",
    "print(test_x.shape,test_x.dtype)\n",
    "print(test_y.shape,test_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(-1,28,28,1).astype(np.float32)/255. #меняем размерность, меняем тип и приводим\n",
    "test_x = test_x.reshape(-1,28,28,1).astype(np.float32)/255.\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) float32\n",
      "(60000,) int32\n",
      "(10000, 28, 28, 1) float32\n",
      "(10000,) int32\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,train_x.dtype)\n",
    "print(train_y.shape,train_y.dtype)\n",
    "print(test_x.shape,test_x.dtype)\n",
    "print(test_y.shape,test_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_samples = train_x[:10, ...] #32 элемента для отображения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAAtCAYAAACNtDBlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATJ0lEQVR4nO2de0wUV/vHn0VWVBAogoIVoa1X3OoWrVpLRFPqpSpqLSARDCZaqy1WElokItWXGKimAbxg1VqaIlUpXkm1lQCiFSXeQ2rxXsBykVcFtkjcnZnv74++Oz9WEXaXhZ1Zzyd5/nBnx32+PHPOfufMOWcVAIjBYDAYDAZDythZOwEGg8FgMBiMjmCGhcFgMBgMhuRhhoXBYDAYDIbkYYaFwWAwGAyG5GGGhcFgMBgMhuRhhoXBYDAYDIbksTflzQqFolvXQANQdOfndbc+IvovAI/u/ECmsUuweY2sLVoeprFLsHmNL3NbZCMs1qXC2gl0A0wjQw68DDVkGhly4IU1ZIaFwWAwGAyG5GGGxUKMHTuWMjMzied5yszMJH9/f2unxGAwbIj09HQCQGVlZeTj42PtdBiMTlFQUECFhYUmndOlhqVHjx7k5uYmRmJiIqWkpNDhw4dp4MCB9NNPPxEAamlpoa+++qorU+lS1Go15efnU2RkJAGgyMhIys/Pt3Za3cJ7771HtbW1NHz4cGunYnESEhKI53kCQIGBgdZOh2Ekffv2JS8vL1q6dCnFx8eTg4ODtVPqNL6+vhQREUGCINDIkSNpxIgR1k7J4gwbNoxGjRpFK1asIADE8/xzcejQIerZs6e1U+0USqWSAgMD6ezZs9ZOxWqkpqbSpEmT6NatWyadZ9Kk244YPHgw9ezZkyZNmkQBAQHk6upKCxYseO599+/fpy1bttD8+fNJo9HQtWvXqLi42JKpdBvjx4+ngwcPkouLCwEgjUZDWq2W+vXrRxMnTqTLly+TVqu1dpovZPLkydSvXz86fPiwWee//fbbdOHCBQtnZX2ioqIoLi6OBEEgIiL2m1vSx9fXl+Li4uidd94hlUolvu7l5UWrVq2yYmadp76+nk6fPk3BwcHWTsXijBo1iqKioigkJITs7Oxo4MCBJAhCm20uODiYvv32W1q9ejU1NTVZIdvO4+LiQkVFRVRbW0uenp5UW1tr7ZS6lZSUFPrkk09Ip9NRQUGBSedazLCo1WoqLCwkFxeXdt8nCAIlJCTQP//8Q9nZ2VRTU0OPHz+mGzduWCqVbqFPnz7k7+9Pe/fuJS8vL/H1W7du0aZNm2j//v109uxZSkhIoOTkZCtm2j5TpkyhoUOHmmVY7Ozs6LXXXiMfHx9SKLp14nqX4+PjQ7169bJ2GhZjwoQJFBERQYGBgTRq1CgiIoqNjaXq6moKCAigvXv3UmlpqZWzNI8RI0bQ6tWradGiRdS7d29SKBRUVVVFGo2GRo4cSaGhoZSRkUHl5eXWTtVsmpubqaLCNueTJicn0wcffGD0+xcvXkx79uyR/QiFp6fnS2lYJk6cSEqlkn7//XfKyckx6VyLGZbKykp6+PBhm4altLSUGhoaaOrUqaTVaikrK8tSH2s1du7cSeHh4c+97u/vT05OTlRcXExTpkyh0aNHWyE741m8eDGdO3fOrHO9vLxo2bJltHfvXll/GTxLUFAQRUdHExFReXk5zZ49m+rq6qyclfmEhYVReno6ubu7k0KhoFOnTpGHhwdt3ryZiIgUCgV5eHjQwoULrZypabi4uNDXX39NYWFh1LdvX/H1W7du0fTp00mpVFJ5eTm5u7uTu7u7FTPtPK6urjRmzBhrp9El5Ofni4blwYMHtGfPHrKzsxNHNydNmmSTj2Rt7SZPz+TJk2nt2rUUHh5Ojx49MjgWHh5OKpWK7ty5Q7Gxsab/5wCMDiJCezFv3jx89913+PTTT8HzPHiex6VLl+Do6AgiwqhRo7Br1652/4/WYUpulghj8xo7diwePXokaiwsLERMTAx4nkdVVRXGjBmDuXPnAgD279/f3v910doa7969i6ysLKNr0jpOnDgBQRCwbt06SWs0JQICAlBVVQWdTgedTofFixcbc54kNdrb22PixIloamoCx3EoLCzE1KlToVQq4eTkhOPHj4PjOPA8j9jYWNm1xaioKHAcZxA3btyAt7c3iAhDhgwRXw8ICJBlDfUxcOBA3LlzBzzPg+M4JCQkwMfHx9TrW5Ia7e3t4e3tDW9vb3h6ej533NnZGZWVlWItc3Nz4eDgICuNrcPd3R2CIEAQBEycONHkPkrq+srLy8HzfJttrqysDAAwf/58s65Tiyfu7OwMhUKBXbt2ged5hIeHm1wQKRdGrVbj0aNHYuPJy8uDk5MTZs2ahfj4eHh4eIjv5XkeGo0G/v7+kmxco0ePRnNzs9mGpaSkxJhGJ/kOpHXs3r1bNKIFBQXGnidJja2/0E+cOAFnZ2fxWEREhHisoqLC4LqVS1v85ZdfRA23b9/Gvn37MHjwYPH4nDlzbMawEBHWrVsnGhaO4/DZZ5+Zen1LXmNbERISAo1GI+pOS0uTtcbWhsWMGkqyLbaOy5cvg+M4BAUFGbyuVqvR1NRkjC/oPsOij82bN4ujD3Z2dmZdqFIrzLBhw5CdnQ2e51FXV4erV6/io48+euH79Z1Ldna2JBvXmjVrIAiCWYZlwIABqKmpgSAI4h2tFDWa2pHwPA+dTof6+npMnTrV2HMlpzEpKUm8/rZs2WJgVogIf/75p/gFMHfuXNm1RaJ/Rx3Wr1+PSZMmoX///s8dX7p0qU0ZltZ9ystiWBYuXIiCggKDUbRnr2W5aXR1dcXjx48hCAJSU1NN/ptIWV9SUhJ0Oh3KysoMboIcHR2xb98+cByHs2fPQqlUmlXDLkvc0dERhYWF4Hke06ZNM+tilVJhHBwccOzYMXAch4aGBkyfPh39+vXDoEGDOuxczpw5I8nGlZmZCUEQsGbNGpNrk5WVBUEQUF5eDldXV1l3IEQEX19fXLp0STQsiYmJppwvKY2JiYngeR4tLS04cuQIevfuLR7r1asXgoOD0dzcDJ7nsWHDBtm1RWNjz549NmdYAIgjgLZsWBYtWoSysjK0tLQYmJWLFy8aXM9y1Xjs2DGbMyze3t6ora1FS0sLAgMDDY7t3LkTHMehsrKyU9epRZc1t6a5uZmWLVtGly9fpt27d1NRURFdvHiRtm/frv8jyIq33npLnBg2d+5c2S7DbgtjlyU7OzvTjBkzKCIigqZNm0ZERElJSdTQ0NCV6XULM2bMECdIFxQUUHp6upUzMg9XV1dauXIlAaDffvuN5s2bJx4bMmQIZWdn09ixY4mIKDc3lzZt2mStVC3OqlWryNHRUfz3m2++SUREJSUlZk8slxovWu4rZ3x9fSkyMpKCgoLE1wICAgx0NjU10Zo1a+j48ePU0tJijTQZ7aBSqejw4cPk7u5OW7duNfh+jI2NpaioKCIi2rhxY+c+qKud5Pz589HQ0CDeFcTFxcHLy0t2TrKkpER8xGWsduDfuyGpj7CEhIQY5DVmzBio1WrExsYiLS0NGRkZaGxshEajwYMHD5CXl4fGxkZwHIcRI0aY7ZatfUegj3nz5qGhoQE6nQ7FxcUYMGCAqde5ZDT2799fvBsdPHgw+vfvj7i4OJw9exaNjY3iqJ9Op8OcOXNkf1fXp08fjBs3Dnl5eWIfo293+knwb7zxhqxq2F7Y2iMhlUqFu3fvPjd5urVOjuNw9OhR2WpsK/QjLD/++KPJ50pJn729PaKiogza3fnz5xEfHw8HBwd4eXmhtLQUWq0W33//fadr2OWF0V+UJ0+eFDuRjIwMvPrqq7IpzOzZs/HkyRNwHIfVq1eb3Lls3bpVko0rIyMDPM/j4cOHuHLlihg8z0MQBGi1WjQ0NKCkpASpqalYtGgRBg0aBKVSibq6Omi1Wtl3IL6+vuJ1yfM8MjMzzbnGJaPR1dUVNTU1bXb6lZWVqKqqAsdxqKmpkW0nSURQKpUYP368qEej0aCqqgo5OTniqii9zi+++AI9e/aUTQ2N6VNsybDcu3fPoA0+azr1MXPmTFlqbCv0hqWhocHkc6Wkr/XkfZ7ncePGDfHf58+fN7e/sa5hof91pJGRkaKw/Px82RQmJCQEHMehurraqNEhBwcHJCcng+d5nDx5Ek5OTpJtXHFxcTh69OhzsWTJkheu/vn4448hCAJu374t+w5kx44d4hJmnU6H4cOHm3N9S0rjhAkTUF9fL3YgmzZtgp+fHzw9PXHq1ClwHGfys3Mp6evZsyeCg4PFjnHdunV49913QURwc3PD1atXn7tjDwsLa28prORq2E4dxC/wnJwcWV+n+vDx8cHatWsxbtw4qFQqg0hNTRVraEuGJSYmRvaGJSwsDDqdDi0tLaipqcHUqVOhVqsNJkm3HtG1xGhnlxfm2Xj69Cl4nsfTp08xZcoUWRRGb1ju3bvXoT4HBwckJSWJy0WnT58u+8b1bBw4cACCIODrr7+WdQeiVqtx584d0azk5uaa+zeRrMbWMXnyZAD/fuFFR0ebdK5U9CmVSiQnJxtsK6Cf9O3h4YELFy6IE443bNiAgwcPiu/99ddfxU5VrVbLsobPjpr5+fnZ3HXaOlxcXGzSsCxYsACCIKC5udnk/XSkoq+wsBB37tzBkiVLDF738/PDmTNnnhvlNeHxl3UNy+jRo/Gf//wHJ06cEO8Orly50uFyZ6kURm9Y0tPT281XrVYjOzsbHMfh4MGDNtO4ng29YTFy0yPJanzw4IFoVs6cOdPeSJhsNbaO6dOnix1IR/uuSLEt9ujRAykpKeA4Do2NjVixYgVeeeUVEBHGjRuH8+fPg+M4lJeXi0vSnZ2dMWPGDGRlZYnzrl5w8yGLGm7fvt3AsHSwJ4ksNbaO0NBQmzQsc+fOhSAIePLkCYYNGya7tkhE+Pzzz9vc0mLy5Ml4/PgxOI5DaGgo/Pz84Ofn19FydKNq2KWFGT58OLZu3Yq///7b4FmkVqvF8ePHZVOY0NBQ8DyPioqKF+YaExMj7n5rCScppcb1bNiKYdEvYdbpdJ3a4FDKGtvSLFfDsmLFCnAch6amJixcuBBubm6YOXMmcnJyxI3FEhMTX7gvUHh4OPLy8pCXl4chQ4bIsobR0dE2YViUSiVmzZrV7hLlJUuWGMxHsiXDQkS4fv06BEFARkaG7Nrii8LFxQVbt24Fz/O4efOmWX+X9mrYJYl7enoiJiZG3Eq6dZSWliI4OFhWhdGPsDx9+hRbtmyBWq2Gt7c3QkJCcOzYMVRUVIDnedy7dw/79u0zZbtl2TSu1nHgwAEAkPW29ZmZmQD+fz6AGducS17jsyH3ERb9ZOLm5mZcunQJ5eXlBl/eCQkJ6NGjh03XkIhw8+ZNg8mpRs4LkIzGgIAAnDhxAhzHtWku3dzcEBERId6l6ydVG7mRoyQ0GhNpaWlobGxEr169ZNcWXxTx8fHiJNv29igzt4YW3YdlwIAB5OfnR9u2baMRI0YYHCstLaXNmzfT0aNHxR+1khs9evSglStX0oIFC6ipqYmGDh0qHispKaGioiJKTEy0YobdBwCys7OzdhpmoVarKSgoiARBIK1WS9u3b5f1jxsay+uvv27tFDpFbW0teXh4kIODg/hDgMePH6fTp0/TkSNH6K+//iKe562cZdfzxx9/iLWUY1+6bds2UqlURET05ZdfkkajMTj+/vvvk7+/v/7Lkk6dOkU7duygoqKibs+1qwFAWq3W2mlYBB8fH1q6dCkBoF27dtH9+/ct/yGWcFpubm74+eefcevWredGVM6cOYN58+Z1tDuhpJ3koEGDcO7cuTb3CKirq+twbks7IZu7gdahfyS0c+dOWWqcMmUKdDodeJ43dqWT7DS2FSqVCsC/o0pyHGHp27cvIiMjkZqaivj4eAwYMMCY5co2VUMiwsyZMw36IrmNsLS1iqutfViqq6uxc+dOU0cgJKHRmEhLS4MgCB39EKAk22JbcfPmTXAchx9++KHL2mKnEp8wYQJyc3NRWVn5nFHRaDTYuHGj+EvN5oSUCuPl5YX169cbGJZvvvmmrWfhNtm4Wof+kRAzLNLV2FGnYuqvxMpF38tQQx8fH5SVlcnWsKjVaoOfTWgdN27cwJUrV7BlyxaoVCqbrmN1dTVaWlqM2XxTFm1R/zjIVANmSg07lXhKSoqBSSkrK0NycjKSkpI6+n0ZWRfGgiGbxtU6oqKiZD3C4unpieLi4pfSsOh/wbmgoMCkJbFy0fcy1NAWNDo4OGD58uWor68Hx3HIzc3F8uXL4enpaTMaO4r9+/fj2rVrsl3WbI3rVPG/hIxCoVAY/2YLAEDRnZ/X3fqI6BKAcd35gUxjlyAbjc7OzpSTk0NBQUF06NAhWrJkCTU3N3d4HmuLlodp7BJsXuPL3BblOWuSwWCYRVNTE4WGhtKOHTvoww8/JB8fH2unxGAwGEbBDAuD8ZLR1NRE0dHRZG9vT9evX7d2OgwGg2EUpi5r/i8RVXRFIm1gjVu/7tRHxDR2FUyjZbF1fURMY1fBNFoWW9dH1I5Gk+awMBgMBoPBYFgD9kiIwWAwGAyG5GGGhcFgMBgMhuRhhoXBYDAYDIbkYYaFwWAwGAyG5GGGhcFgMBgMhuRhhoXBYDAYDIbkYYaFwWAwGAyG5GGGhcFgMBgMhuRhhoXBYDAYDIbk+T8qlnIqdTW9hgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Отображаем данные с помощью matpotlib\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for j in range(some_samples.shape[0]):\n",
    "    ax = fig.add_subplot(10,10,j+1)\n",
    "    ax.imshow(some_samples[j,:,:,0],cmap = 'gray')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#tf.data — пакет внутри tensorflow, который предоставляет различные удобные функции для работы с данными. \n",
    "#Dataset. from_tensor_slices — класс с функцией, которая сделает нам датасет с тензорами\n",
    "#С помощью цепной последовательности функции можно модифицировать \n",
    "#Обучение будет происходить в несколько эпох. Одна эпоха = один показ датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=train_x.shape[0])#перемешиваем данные в датас"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.repeat(NUM_EPOCHS)#устанавливаем колличество эпох "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE)#устанавливем батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import layers\n",
    "class Model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "    \n",
    "        self.Conv1 =  tf.layers.Conv2D(32,(5,5),activation = tf.nn.relu,padding = 'same')\n",
    "        self.Conv2 = tf.layers.Conv2D(64,(5,5),activation = tf.nn.relu,padding = 'same')\n",
    "        self.Fc1 = tf.layers.Dense(256,activation = tf.nn.relu)\n",
    "        self.Fc2 = tf.layers.Dense(10,activation = None)\n",
    "        self.MaxPooling =tf.layers.MaxPooling2D((2,2),(2,2),padding = 'same')\n",
    "    def __call__(self,inp):\n",
    "        out = self.Conv1(inp)\n",
    "        out = self.MaxPooling(out)\n",
    "        out = self.Conv2(out)\n",
    "        out = self.MaxPooling(out)\n",
    "        out = tf.layers.flatten(out)\n",
    "        out = self.Fc1(out)\n",
    "        out = self.Fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Вычисляем ошибку\n",
    "def loss(logits,labels):\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Вычисляем точность\n",
    "def accuracy(logits, labels):\n",
    "    prdictions = tf.argmax(logits,axis=1,output_type = tf.int32)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(prdictions,labels),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)#создаем опимизатор на базе градиентного спуска\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)#создаем опимизатор на базе градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer =tf.contrib.summary.create_file_writer(\"logs/adam_maxim\") #запишем логи работы в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step() #номер глобального шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-d290786c6a06>:17: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "[ 200] Accuary: 94.53 %\n",
      "[ 400] Accuary: 97.66 %\n",
      "[ 600] Accuary: 98.05 %\n",
      "[ 800] Accuary: 98.05 %\n",
      "[1000] Accuary: 99.61 %\n",
      "[1200] Accuary: 100.00 %\n",
      "[1400] Accuary: 99.22 %\n",
      "[1600] Accuary: 99.61 %\n",
      "[1800] Accuary: 100.00 %\n",
      "[2000] Accuary: 100.00 %\n",
      "[2200] Accuary: 100.00 %\n",
      "[2400] Accuary: 100.00 %\n",
      "[2600] Accuary: 100.00 %\n",
      "[2800] Accuary: 100.00 %\n",
      "[3000] Accuary: 99.61 %\n",
      "[3200] Accuary: 100.00 %\n",
      "[3400] Accuary: 100.00 %\n",
      "[3600] Accuary: 100.00 %\n",
      "[3800] Accuary: 99.61 %\n",
      "[4000] Accuary: 99.61 %\n",
      "[4200] Accuary: 99.22 %\n",
      "[4400] Accuary: 100.00 %\n",
      "[4600] Accuary: 99.22 %\n",
      "[4800] Accuary: 100.00 %\n",
      "[5000] Accuary: 99.61 %\n",
      "[5200] Accuary: 100.00 %\n",
      "[5400] Accuary: 99.61 %\n",
      "[5600] Accuary: 100.00 %\n",
      "[5800] Accuary: 100.00 %\n",
      "[6000] Accuary: 100.00 %\n",
      "[6200] Accuary: 100.00 %\n",
      "[6400] Accuary: 99.22 %\n",
      "[6600] Accuary: 99.61 %\n",
      "[6800] Accuary: 100.00 %\n",
      "[7000] Accuary: 100.00 %\n",
      "[7200] Accuary: 100.00 %\n",
      "[7400] Accuary: 99.61 %\n",
      "[7600] Accuary: 99.61 %\n",
      "[7800] Accuary: 99.61 %\n",
      "[8000] Accuary: 99.61 %\n",
      "[8200] Accuary: 99.61 %\n",
      "[8400] Accuary: 98.83 %\n",
      "[8600] Accuary: 100.00 %\n",
      "[8800] Accuary: 100.00 %\n",
      "[9000] Accuary: 100.00 %\n",
      "[9200] Accuary: 99.61 %\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for (images,labels) in train_ds:\n",
    "    \n",
    "    #forward шаг 1 - прямое распространение\n",
    "    #создание градиентной ленты\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(images)\n",
    "        loss_value = loss(logits,labels)\n",
    "    \n",
    "    #backward 2 шаг - обратное распространение ошибки\n",
    "    grads = tape.gradient(loss_value,model.variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.variables),global_step=global_step)\n",
    "    \n",
    "    #шаг 3\n",
    "    \n",
    "    if global_step.numpy() % 200 == 0:\n",
    "        test_logits=model(test_x[:256,...])\n",
    "        accuracy_value=accuracy(test_logits,test_y[:256,...])\n",
    "        \n",
    "        print(\"[%4d] Accuary: %5.2f %%\" % (global_step.numpy(),accuracy_value.numpy()*100))\n",
    "        with writer.as_default():\n",
    "            with tf.contrib.summary.always_record_summaries():\n",
    "                tf.contrib.summary.scalar('accuracy',accuracy_value)\n",
    "                tf.contrib.summary.scalar('loss',loss_value)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 99.12 %\n"
     ]
    }
   ],
   "source": [
    "test_logits = model(test_x)\n",
    "accuracy_value = accuracy(test_logits, test_y).numpy()\n",
    "\n",
    "print(\"Final Accuracy: %5.2f %%\" % (accuracy_value * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
